{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import simplemma\n",
    "import os\n",
    "from simplemma import text_lemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "for path, subdirs, files in os.walk(\"plain_texts/Cze\"):\n",
    "    for name in files:\n",
    "        file_path = os.path.join(path,name)\n",
    "        with open(file_path) as file:\n",
    "            text = file.read()\n",
    "        \n",
    "        paragraphs = text.split(\"\\n\")\n",
    "        result = [text_lemmatizer(p, lang='cs') for p in paragraphs]\n",
    "        joined_lines = [\"\\n\".join(x) for x in result]\n",
    "        joined_text = \"\\nEOL\\n\".join(joined_lines) \n",
    "            \n",
    "        new_name = os.path.splitext(name)[0]\n",
    "        new_path = os.path.join(\"lemmatized_texts/Cze/\", new_name+\"_lemmatized.txt\")\n",
    "        with open(new_path, 'w+') as output:\n",
    "            output.write(joined_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ben\n",
    "fn = \"ELTeC_originals/Cze/level1/CS0035_1876_Svetla_Cerny-petricek.xml\"\n",
    "with open(fn,'r') as fh:\n",
    "    s = BeautifulSoup(fh, 'lxml')\n",
    "# Ben\n",
    "tags = s.find('text').find_all('p')\n",
    "all_str = (\"\\n\").join([t.text for t in tags])\n",
    "with open('tst.txt', 'w') as of:\n",
    "    of.write(all_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test na jednym\n",
    "with open(\"ELTeC_originals/Cze/level1/CS0035_1876_Svetla_Cerny-petricek.xml\") as file:\n",
    "    soup = BeautifulSoup(file, 'lxml')\n",
    "    tags = soup.find('text').find_all('p')\n",
    "    stripped = (\"\\n\").join([t.text for t in tags])\n",
    "    with open('test.txt', 'w') as output:\n",
    "        output.write(stripped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "for path, subdirs, files in os.walk(\"plain_texts/Pol\"):\n",
    "    for name in files:\n",
    "        file_path = os.path.join(path,name)\n",
    "        \n",
    "        with open(file_path) as file:\n",
    "            text = file.read()\n",
    "            \n",
    "        paragraphs = text.split(\"\\n\")\n",
    "        result = [text_lemmatizer(p, lang=\"pl\") for p in paragraphs]\n",
    "        joined_lines = [\"\\n\".join(x) for x in result]\n",
    "        joined_text = \"\\nEOL\\n\".join(joined_lines)\n",
    "        \n",
    "        new_name = os.path.splitext(name)[0]\n",
    "        new_path = os.path.join(\"lemmatized_texts/Pol/\", new_name+\"_lemmatized.txt\")\n",
    "        with open(new_path, 'w+') as output:\n",
    "            output.write(joined_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
